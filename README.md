# ğŸ¤– Persian QA Chatbot on Linux & Free Software Philosophy

This project builds a **conversational QA chatbot** that answers user questions based on data gathered from various sources such as PDF/Epub files, Wikipedia pages, websites, and more. The content revolves around the **philosophy of Linux**, **free software**, and the **key figures** who have shaped these movements.

---

## ğŸ“˜ Project Overview

This project demonstrates how to build a Persian-language **Question Answering (QA)** system using [LangChain](https://www.langchain.com/), Cohere multilingual embeddings, and a FAISS vectorstore.

It integrates information from **PDFs, websites, Wikipedia pages, and HTML documents**, preprocesses them, generates embeddings, and enables natural language querying in Persian.

---

## Features

- âœ… Load and clean PDF content (e.g., _Just for Fun_ in Persian)
- âœ… Scrape and load a Persian Linux blog (`https://linuxbook.ir`)
- âœ… Extract Farsi articles from Wikipedia
- âœ… Load local HTML files
- âœ… Clean and preprocess Persian text
- âœ… Chunk documents with overlap using LangChain
- âœ… Embed using Cohere's `embed-multilingual-light-v3.0`
- âœ… Store embeddings using FAISS vectorstore (locally)
- âœ… Perform retrieval-based question answering with `command-r-plus` model
- âœ… Apply MMR (Maximal Marginal Relevance) for diverse document retrieval

---

## ğŸ“ Data Sources

| Type      | Source                                                                 |
|-----------|------------------------------------------------------------------------|
| PDF       | `justforfun_persian.pdf` â€” Biography of Richard Stallman              |
| Website   | [`https://linuxbook.ir/all.html`](https://linuxbook.ir/all.html)      |
| Wikipedia | Articles on Stallman, Linus Torvalds, GNU Project, Free Software, etc.|
| HTML      | Local files inside `data/html`                                         |

---

## âš™ï¸ Pipeline Overview

1. **Document Loading**: Load PDFs, web pages, Wikipedia, and HTML using LangChain community loaders.
2. **Text Cleaning**: Normalize and clean Persian text to remove invisible and redundant characters.
3. **Chunking**: Split documents into overlapping chunks (500 chars, 50 overlap) using recursive splitter.
4. **Embedding**: Use Cohereâ€™s multilingual embedding model to convert chunks into dense vectors.
5. **Vectorstore**: Store chunks and their embeddings in a FAISS index with metadata.
6. **Retrieval QA**: Use an LLM (`command-r-plus`) to answer user questions based on top-k retrieved chunks.

---

## ğŸ›  Requirements & Setup

- Python 3.9
- Install dependencies via:
  
  ```bash
  pip install -r requirements.txt
  ```

  . Make sure to set your Cohere API key in the script before running.

  . Data files (PDFs, HTML, etc.) should be placed in the appropriate data/ directories.

---
## ğŸ™ Acknowledgments

This project is developed as part of the **Quera LLM Course**.  

